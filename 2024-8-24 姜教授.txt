TODO List
1. 输入的数据来源和评估的数据benchmark
已经有用于训练的数据和用于测试的数据

数据来源的描述
2.3 Benchmark choices-> 3 Dataset Description
基于Gretel.ai生成的训练数据
答案有instruction等详细过程，可以在论文用一些示例做具体说明

基于GPT-4o finetuning test data的测试数据
出处？来自于前人的文献或研究
Theorem QA [CYK+23] to test theorems of math
MATH [HBK+21], the Algebra category contains linear algebra
有一些现有的评估结果，抽取了我们想要评估的部分，是前人测试集合的一个子集

2. 论文的写作部分
Introduction还可以有更多大模型方面的general Background
有点类似于Related Work第一段，但可以在Introduction部分多提一些
可以多提一些大模型发展的背景和驱动的因素
训练的成本具象化，目前的训练成本是多少，主要开销大概是怎么衡量，然后有没有可能降下来

3. LLaMA模型的实现
本地：服务器
云端：Cloud server

知道一些预训练过的大模型下载到本地
下载下来之后的微调和运行还没有尝试过？
可以通过租服务器来实现

GPT-4o mini, LLaMA 13B, 

4. 有没有快速做一个验证
用公开的网页版或者直接调API先对测试集做一个评估？
general pre-trained LLM也许在specific math task表现不好
看看这个有没有可能自动化地测试一下
数据格式采用json格式
可能得先看下API能不能做一个自动评估

5. 评估指标
Accuracy
https://docs.llamaindex.ai/en/stable/module_guides/evaluating/
第三方工具
可以快速做一些评估
https://docs.llamaindex.ai/en/stable/examples/finetuning/openai_fine_tuning/
类似上面的流程

6. Methodology
可以介绍一些大模型的机理
介绍fine tuning的一些基本概念
这些部分也可以写