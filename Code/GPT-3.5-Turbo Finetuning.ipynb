{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Setup OpenAI API client\n",
    "#client = OpenAI()\n",
    "\n",
    "# Function to get model completion\n",
    "def get_answer(question, model_name):\n",
    "    response = client.chat.completions.create(\n",
    "        model= model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that only provides direct answers without any explanations.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Introduce another state-of-the-art model such as GPT-4 to evaluate model performace\n",
    "def evaluation(benchmark_answer, generated_answer):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Decide if the benchmark answer and the generated answer match. Respond with 'True' if they match, otherwise 'False'.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Benchmark Answer: {benchmark_answer}\\nGenerated Answer: {generated_answer}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip().lower() == 'true'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(file_path, generate_model_name):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    correct_count = 0\n",
    "    total_count = len(data)\n",
    "\n",
    "    for item in data:\n",
    "        question = item[\"Question\"]\n",
    "        benchmark_answer = item[\"Answer\"]\n",
    "        generated_answer = get_answer(question, generate_model_name)\n",
    "        match = evaluation(benchmark_answer, generated_answer)\n",
    "        if match:\n",
    "            correct_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_algebra_path = \"Data/Test Data/MMLU,Theorem QA, Linear Algebra QA/abstract_algebra_qa_test.json\"\n",
    "linear_algebra_qa_path = \"Data/Test Data/MMLU,Theorem QA, Linear Algebra QA/linear_algebra_qa.json\"\n",
    "linear_algebra_theorem_qa_test_path = \"Data/Test Data/MMLU,Theorem QA, Linear Algebra QA/linear_algebra_theorem_qa_test.json\"\n",
    "linear_algebra_data_test_path = \"Data/Test Data/MATH Linear Algebra/linear_algebra_data_test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 22.00%\n"
     ]
    }
   ],
   "source": [
    "benchmark(abstract_algebra_path, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.84%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_qa_path, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.62%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_theorem_qa_test_path, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.60%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_data_test_path, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuned GPT-3.5-Turbo with two different datasets for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.files.create(\n",
    "  file=open(\"Data/Finetuning Data/abstract_algebra_finetuning_chat.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-87NJ25RTZ7X3On8UwBTqMwNm', bytes=3874885, created_at=1726508810, filename='combined_finetuning_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9000 combined finetuning data for GPT-3.5-turbo and GPT-4o-mini\n",
    "client.files.create(\n",
    "  file=open(\"Data/Finetuning Data/combined_finetuning_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-4z4gAcbj2gbjPKdwyqSSSLg4', created_at=1726508851, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-5UJP7VuDIG8zyGaxVePAnKpw', result_files=[], seed=896923282, status='validating_files', trained_tokens=None, training_file='file-87NJ25RTZ7X3On8UwBTqMwNm', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-87NJ25RTZ7X3On8UwBTqMwNm\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters(n_epochs=2, batch_size=12, learning_rate_multiplier=2) for GPT-3.5-turbo Combined Training Data\n",
      "Hyperparameters(n_epochs=3, batch_size=6, learning_rate_multiplier=2) for GPT-3.5-turbo Abstract Algebra Training Data Only\n"
     ]
    }
   ],
   "source": [
    "print(client.fine_tuning.jobs.retrieve(\"ftjob-4z4gAcbj2gbjPKdwyqSSSLg4\").hyperparameters, \"for GPT-3.5-turbo Combined Training Data\")\n",
    "print(client.fine_tuning.jobs.retrieve(\"ftjob-9N1bLQqiWzpTnssk2RIwW2nt\").hyperparameters, \"for GPT-3.5-turbo Abstract Algebra Training Data Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.00%\n"
     ]
    }
   ],
   "source": [
    "benchmark(abstract_algebra_path, \"ft:gpt-3.5-turbo-0125:personal::A74brutO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.00%\n"
     ]
    }
   ],
   "source": [
    "benchmark(abstract_algebra_path, \"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.98%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_qa_path, \"ft:gpt-3.5-turbo-0125:personal::A74brutO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.22%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_qa_path, \"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Theorem QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.31%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_theorem_qa_test_path, \"ft:gpt-3.5-turbo-0125:personal::A74brutO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.00%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_theorem_qa_test_path, \"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATH QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.90%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_data_test_path, \"ft:gpt-3.5-turbo-0125:personal::A74brutO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.65%\n"
     ]
    }
   ],
   "source": [
    "benchmark(linear_algebra_data_test_path, \"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs Comparison of GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Let A and B be sets, f: A -> B and g: B -> A be functions such that for all a \\in A, g(f(a)) = a. Statement 1 | The function f must necessarily be injective. Statement 2 | The function f must necessarily be surjective.\n",
      "Expected Answer: True, False\n",
      "\n",
      "Original Model Answer: Statement 1: True\n",
      "Statement 2: False\n",
      "Fine-tuned Model Answer: Statement 1: False. The function f(a) can still be non-injective. Consider f(a) = f(b) for some a, b \\in A, then a = g(f(a)) = g(f(b)) = b. It means g is injective. Statement 2: True. The function g is surjective because it is defined from B \\to A, and for all a \\in A, g(f(a)) = a.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_sample_response(file_path, number,original_model_name, finetuned_model_name):\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if data:\n",
    "        first_item = data[number]  # Using the 11th question as requested (index 10)\n",
    "        question = first_item[\"Question\"]\n",
    "        benchmark_answer = first_item[\"Answer\"]\n",
    "\n",
    "        # Get answers from the original and fine-tuned models\n",
    "        original_answer = get_answer(question, original_model_name)\n",
    "        finetuned_answer = get_answer(question, finetuned_model_name)\n",
    "\n",
    "        # Display the question and the expected benchmark answer\n",
    "        print(\"Question:\", question)\n",
    "        print(\"Expected Answer:\", benchmark_answer)\n",
    "\n",
    "        # Display the answers from both models\n",
    "        print(\"\\nOriginal Model Answer:\", original_answer)\n",
    "        print(\"Fine-tuned Model Answer:\", finetuned_answer)\n",
    "\n",
    "    else:\n",
    "        print(\"No data available.\")\n",
    "\n",
    "display_sample_response(\"Data/Test Data/MMLU,Theorem QA, Linear Algebra QA/abstract_algebra_qa_test.json\", 44,\"gpt-3.5-turbo\",\"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: If v1, v2, and v3 are linearly independent, can you find a linear combination of these vectors that has a magnitude of 3? How do you know?\n",
      "Expected Answer: Yes, you can find a linear combination of v1, v2, and v3 that has a magnitude of 3.\n",
      "\n",
      "To find a linear combination of v1, v2, and v3 that has a magnitude of 3, you can use the fact that if v1, v2, and v3 are linearly independent, then any linear combination of these vectors can be written in the form:\n",
      "\n",
      "a1v1 + a2v2 + a3v3 = 0\n",
      "\n",
      "where a1, a2, and a3 are constants.\n",
      "\n",
      "Since v1, v2, and v3 are linearly independent, we know that none of these vectors are multiples of the others. Therefore, the only non-trivial linear combination of v1, v2, and v3 is:\n",
      "\n",
      "v1 + v2 + v3 = 0\n",
      "\n",
      "This linear combination has a magnitude of 3, since the magnitude of the vector is equal to the product of its components.\n",
      "\n",
      "Therefore, the answer to the question is yes, you can find a linear combination of v1, v2, and v3 that has a magnitude of 3.\n",
      "\n",
      "Original Model Answer: Yes, the linear combination would be a non-trivial one of the vectors, for example, 3v1. This linear combination will be collinear with v1, and its magnitude will be 3 times the magnitude of v1.\n",
      "Fine-tuned Model Answer: Yes, the linear combination of v1, v2, and v3 is 3v1 = 3v2 = 3v3, which has a magnitude of 3. Since v1, v2, and v3 are linearly independent, they are not scalar multiples of each other. Therefore, the linear combination of the vectors that has a magnitude of 3 is valid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_sample_response(\"Data/Test Data/MMLU,Theorem QA, Linear Algebra QA/linear_algebra_qa.json\", 24,\"gpt-3.5-turbo\",\"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is 7 a quadratic residue modulo 19? Use Gauss's Lemma to answer it.\n",
      "Expected Answer: True\n",
      "\n",
      "Original Model Answer: Yes, 7 is a quadratic residue modulo 19.\n",
      "Fine-tuned Model Answer: \\[7 = -1\\mod 19\\] \\\\ \\[7^{(19-1)/2} = (-1)^{9} = -1\\mod 19\\] \\\\ \\[7\\] is a quadratic nonresidue modulo 19.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_sample_response(linear_algebra_theorem_qa_test_path, 19,\"gpt-3.5-turbo\",\"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Find the determinant of the matrix $\\left( \\begin{array}{cc} -4 & -2 \\\\ -1 & -4 \\\\ \\end{array} \\right)$. \n",
      "Expected Answer: $14$\n",
      "\n",
      "Original Model Answer: The determinant of the matrix is 14.\n",
      "Fine-tuned Model Answer: The determinant of the matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ is calculated as ad - bc. In this case, the determinant is (-4)(-4) - (-2)(-1) = 16 - 2 = 14.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_sample_response(linear_algebra_data_test_path, 1,\"gpt-3.5-turbo\",\"ft:gpt-3.5-turbo-0125:personal::A8AuHZhq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5400",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
